# Walking Cheetah learning with PPO

Used a micromamba environment for versioning:

- Python version: `3.12`.